{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdHbgJ4EHmij"
   },
   "source": [
    "# <font color='gray'> Lab sessions 2 and 3: Regression </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ln31kjtrKhgK"
   },
   "source": [
    "## Introduction \n",
    "\n",
    "The aim of this lab is to get experience with **regression problems**, the concepts of **under/over-fitting**, and **cross-validation**. This lab will use both **python** and **Weka**. \n",
    "\n",
    "- This is the manual for a two-week lab exercise (*week 3* and *week 4*). \n",
    "- It is also the **first assignment** and **should be delivered by the end of week 4** (for a contribution of 6% of your overall grade).\n",
    "- Questions in <font color = 'red'>**red**</font> (well, actually, in <font color = 'maroon'>**this red!**</font>) are assessed towards your final grade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obg-6wLVUgk_"
   },
   "source": [
    "## Important notes about grading: \n",
    "\n",
    "- **PLAGIARISM** <ins>is an irreversible non-negotiable failure in the course</ins> (if in doubt of what constitutes plagiarism, ask!). \n",
    "- The total assessed coursework is worth 30% of your final grade.\n",
    "- There will be 10 lab sessions and 5 assignments.\n",
    "- One assignment will cover 2 consecutive lab sessions and will be worth 6 marks (percentages of your final grade).\n",
    "- The deadline for submitting each coursework is 12 days after the first lab session (Tuesday).\n",
    "- There will be no opportunity to submit after the deadline (the submission link will disappear).\n",
    "- The report should answer the <font color = 'red'>**questions in</font><font color = \"maroon\"> red**</font> only. This should be a separate file in **pdf format** (so **NOT** *doc, docx, notebook* etc.). It should be well identified with your name, student number, assignment number (for instance, Assignment 1), module, and marked with question numbers. \n",
    "- No other means of submission other than the appropriate QM+ link is acceptable at any time (so NO email attachments, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7L4DNPvPxf9"
   },
   "source": [
    "## 0. Regression and Over-fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nm294F7-Zmrw"
   },
   "source": [
    "The\t point\t of\t this\texercise\tis\t to\t understand\t\n",
    ">i)\t**over-fitting**;\n",
    "<br>\n",
    ">ii)\thow **over-fitting affects\t train\t and\t test\t error** differently,\t and;\n",
    "<br>\n",
    "iii)\t how\t it\t depends\t on\t the **complexity of the model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3RNGFfzWci8"
   },
   "source": [
    "0.  First, let's \"load\" our data. The first exercise is very simple, so we are going to give the data explicitly as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSPDh4hhR841"
   },
   "outputs": [],
   "source": [
    "# traing data\n",
    "xTrain =[0.3000, -0.7700, 0.9000, -0.0400, 0.7400, -0.5800, -0.9200, -0.2100, -0.5400, 0.6800]\n",
    "yTrain =[1.1492, 0.3582, 1.9013, 0.9487, 1.3096, 0.9646, 0.1079, 1.1262, 0.6131, 1.0951]\n",
    " \n",
    "# testing date\n",
    "xTest =[0.1100, 0.2300, 0.1800, 0.3500, 0.5200, -0.4400, -0.6900, -0.2400, 0.4300, -0.4100, 0.3300, 0.8800, -0.4300, 0.5600, 0.6600, -0.0100, -0.8300, 0.5700, 0.3400, 0.6700]\n",
    "yTest =[1.0569, 1.0647, 0.9575, 1.2097, 0.8371, 0.8573, 0.6128, 1.1087, 0.9253, 0.9788, 1.0590, 1.6263, 0.7660, 1.0799, 1.3341, 0.6867, 0.3657, 1.1747, 1.0440, 1.1315]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGNzyWu4XJul"
   },
   "source": [
    " 1. We have loaded four variables. What are they? Let's explore one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T80DcTU4Xwet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, -0.77, 0.9, -0.04, 0.74, -0.58, -0.92, -0.21, -0.54, 0.68]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(xTrain)\n",
    "print(len(xTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IxN5LBXXy_d"
   },
   "source": [
    "---\n",
    "> **Q0:** Note that the dimensions of the `xTrain` are 10x1. \n",
    "This means we are dealing with a ?-dimensional regression problem with ?? instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRYOXxLl3rMz"
   },
   "source": [
    "> **A0:** 1-dim 10 instances(*Recall that you can use this space to write your answer by double-click on this cell. This is only for your own note-taking. The answers to the red questions -- hence, not this one, for instance! -- should be written in a separate document and submitted through QM+ as a single **pdf** file, as we detailed above.*) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPPui6Q2-Fi2"
   },
   "source": [
    "2. Let's plot our train and test data-sets. The x-axis will be our predictor attribute and the y-axis is the label (target). The train and test data-sets are plotted with different markers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2n98UA8Y-hYd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(7,7))\n",
    "plt.plot(xTrain, yTrain, 'o', label=\"Train Data\")\n",
    "plt.plot(xTest, yTest, '*', label=\"Test Data\")\n",
    "plt.xlabel(\"x (attribute)\", fontsize=18)\n",
    "plt.ylabel(\"y (label)\", fontsize=18)\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.5,2.5)\n",
    "# plt.gca().set_aspect('equal')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBSeW7KAEmbi"
   },
   "source": [
    "3. The following code **fits** a 1$^{st}$ order polynomial (i.e., a simple line) to the presented data using least squares. This means that it finds the line that predicts the label in the train data with minimum mean squared error (MSE). We also print the corresponding equation with the estimated values for the parameters of that equation (i.e., the learned model) along with the MSE in the train and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "4vDmxUwQddIy"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learned model is:\n",
      "  \n",
      "0.6621 x + 0.9865\n",
      "---\n",
      "Train MSE:  0.05434\n",
      "Test MSE:  0.04653\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "order = 1\n",
    "p = np.poly1d(np.polyfit(xTrain, yTrain, order))\n",
    "#p_test = np.poly1d(np.polyfit(xTest,yTest,order))\n",
    "t = np.linspace(-1, 1, 201)\n",
    "\n",
    "plt.plot(xTrain, yTrain, 'o', label=\"Train Data\")\n",
    "plt.plot(xTest, yTest, '*', label=\"Test Data\")\n",
    "plt.plot(t, p(t), '-', label=\"Fitted Model\", linewidth=2)\n",
    "plt.xlabel(\"x (attribute)\", fontsize=18)\n",
    "plt.ylabel(\"y (label)\", fontsize=18)\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.5,2.5)\n",
    "# plt.gca().set_aspect('equal')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print('The learned model is:\\n {}\\n---'.format(p))\n",
    "    \n",
    "MSE_Train = sum((p(x) - y)**2 for x, y in zip(xTrain, yTrain))/len(yTrain)\n",
    "print('Train MSE: {:8.5f}'.format(MSE_Train))\n",
    "\n",
    "MSE_Test = sum((p(x) - y)**2 for x, y in zip(xTest, yTest))/len(yTest) #0\n",
    "print('Test MSE: {:8.5f}'.format(MSE_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBC-BGDG3WPN"
   },
   "source": [
    "---\n",
    "> **Q1:** There is an intentional mistake in the code: the mean-squared-error (MSE) for the test dataset is computed wrongly. Fix it! \n",
    "\n",
    "  *Hint 1: you can get the idea from how the MSE for the train data is computed, and write the code for the MSE_Test accordingly.*\n",
    "\n",
    "  *Hint 2: if you are still in doubt, look at the code cell in the next task, you can actually find it there, but use it as a double-check.*\n",
    "\n",
    "  *Hint 3: note that indentation is very important in Python. There are no `begin` and `end` or curly brackets { } in Python, and code blocks are demarcated by their indentation (loops, if statements, body of functions, etc).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoVzphxEIGIY"
   },
   "source": [
    "> **Q2:** Which function in the above code is responsible for finding the best model for a given order (i.e., fit the model)? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8w-qJxp5IyKa"
   },
   "source": [
    "> **A2:** np.poyfit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biRUSEDKIztq"
   },
   "source": [
    "> **Q3:** Edit the code so that you find the best model for higher degrees of polynomials. That is, fit 2$^{nd}$, 3$^{rd}$, ..., 9$^{th}$ order polynomials to the training data. What do you observe about the different fits in terms of their match to training and test data, respectively? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_R2CndbJsbk"
   },
   "source": [
    "> **A3:**  Train MSE decreases but Test MSE increases\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMPpV1UZLrLY"
   },
   "source": [
    "4. Let's put all of the polynomial orders side-by-side for an easier comparison! Run the following code block **twice** (to get the tabular view). You can then change between the tabs. Note the train MSE and test MSE for each fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwPZ3bnF_dpw"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-595b2fa56be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# stil analyse the outputs!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0morders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Don't forget to run this cell twice to get the tabs (some weird bug with the \n",
    "# colab interface it seems!) If you don't get the tab view, it is fine, you can\n",
    "# stil analyse the outputs!\n",
    "\n",
    "from google.colab import widgets\n",
    "\n",
    "orders = range(1,10)\n",
    "t = np.linspace(-1, 1, 201)\n",
    "\n",
    "tb = widgets.TabBar([str(order) for order in orders])\n",
    "for order in orders:\n",
    "  with tb.output_to(str(order), select= (order < 2)):\n",
    "    p = np.poly1d(np.polyfit(xTrain, yTrain, int(order)))\n",
    "\n",
    "    plt.plot(xTrain, yTrain, 'o', label='Train data')\n",
    "    plt.plot(xTest, yTest, '*', alpha=0.6, label='Test data')\n",
    "    plt.plot(t, p(t), '-', alpha=0.8, label='Learned model', linewidth=2)\n",
    "    plt.xlabel(\"x\", fontsize=14)\n",
    "    plt.ylabel(\"y\",fontsize=14)\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-0.5,2.5)\n",
    "    # plt.gca().set_aspect('equal')\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.legend(loc='upper left', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    print('The learned (fitted) model is:\\n {}\\n---'.format(p))\n",
    "\n",
    "    MSE_Train = sum((p(x) - y)**2 for x, y in zip(xTrain, yTrain))/len(yTrain)\n",
    "    print('Train MSE: {:8.5f}'.format(MSE_Train))\n",
    "\n",
    "    MSE_Test = sum((p(x) - y)**2 for x, y in zip(xTest, yTest))/len(yTest)\n",
    "    print('Test MSE: {:8.5f}'.format(MSE_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlPPflCKPK83"
   },
   "source": [
    "5. Let's make the comparison of MSE values more systematic: let's save the MSE of each model for both train and test data into two lists and plot them. The x-axis is the order of the polynomial of the fitted model, a measure of complexity (flexibility) of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJcBEZe_WTxx"
   },
   "outputs": [],
   "source": [
    "orders = range(1,10)\n",
    "MSE_Trains = dict.fromkeys(orders)\n",
    "MSE_Tests = dict.fromkeys(orders)\n",
    "\n",
    "for order in orders:\n",
    "  p = np.poly1d(np.polyfit(xTrain, yTrain, int(order)))\n",
    "  MSE_Trains[order] = sum((p(x) - y)**2 for x, y in zip(xTrain, yTrain))/len(yTrain)\n",
    "  MSE_Tests[order] = sum((p(x) - y)**2 for x, y in zip(xTest, yTest))/len(yTest)\n",
    "  \n",
    "plt.plot(orders, MSE_Trains.values(), '--o', label='MSE Train', linewidth=2)\n",
    "plt.plot(orders, MSE_Tests.values(), '--*', label='MSE Test', linewidth=2)\n",
    "\n",
    "plt.title('''Fig 0: Comparison of Train and Test MSE (no regularisation).\\n\n",
    "You should be able to describe and explain the general trend in each graph, \n",
    "and identify the cases of underfitting and overfitting.\\n''', fontsize=14)\n",
    "plt.xlabel(\"Order (degree of the fitted polynomial)\", fontsize=12)\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\", fontsize=12)\n",
    "plt.xlim(1,9)\n",
    "plt.ylim(0,0.1)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RAOmmdoWE8H"
   },
   "outputs": [],
   "source": [
    "print(MSE_Trains)\n",
    "print(MSE_Tests)\n",
    "print('Min Train MSE: {:1.30f}'.format(min(MSE_Trains.values())))\n",
    "print('Min Test MSE: {:8.5f}'.format(min(MSE_Tests.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xc53RPzaPndH"
   },
   "source": [
    "---\n",
    "---\n",
    "#### <font color=\"maroon\"><b>Exercise 0: </b> Which polynomial has the lowest `train` MSE? Which one has the lowest `test` MSE? <b>[0.5 mark]</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57D5doeaWwfn"
   },
   "source": [
    "Answer: Order 9 has minimum value MSE for training (7.737735706301106e-27) and \n",
    "Order 3 has minimum value MSE for testing (0.016317893338617738) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G37HPZaxPnJn"
   },
   "source": [
    "####<font color=\"maroon\"><b>Exercise 1: </b> What trend do you observe when you analyse the dependence of train and test MSE on the polynomial order? First describe the observed trends, and then explain them. <b>[1 mark]</b>  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pa_fDDo6Y053"
   },
   "source": [
    "The Mean Square Error (MSE) for both training and testing data sharply decreases with 3rd degree polynomial and reaches to an approximate value of 0.02. This trend of lower MSE continues with both Training and Testing MSE diverging in opposite directions as we increase the degree of polynomial until degree 8 and then overshoots for polynomial degree 9. \n",
    "The covergence can be seen at polynomial degree 3 before this the model is too ridgid and at degree 9 we can see overfitting as the model has memorised all the points instaed of learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NsNx0hmqUtHq"
   },
   "source": [
    "####<font color=\"maroon\"><b>Exercise 2: </b> Identify the models that are suffering from <u>under-fitting</u> and the ones suffering from <u>over-fitting</u>. Justify your choice based on your observations and use the theory that we have learnt to explain it. <b>[0.5 mark]</b>  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0b7mdtaQb8zD"
   },
   "source": [
    "Underfitting can be seen with first degree polynomial the model is to ridgid and genralisation for newer data is poor as the MSE for train is high. \n",
    "\n",
    "Overfitting can be seen after degree 7 polynomial as the model is too generalised and as the model tries to fit all the point of the given Training data the learning capability is lost instead it is trying to memorise the traing data, which is why it fails misreably and we see higher Test and Training MSE.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1noA8yFATSK2"
   },
   "source": [
    "####<font color=\"maroon\"><b>Exercise 3: </b> Which model would you pick as the best one amongst these 9 models? What are the parameter(s) and hyper-parameter(s) of your chosen model? <b>[0.5 mark]</b>  </font>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5pK_Ee7b8IH"
   },
   "source": [
    "Polynomial model of degree 3 and the model is y =  1.326 x^3 - 0.09076 x^2 - 0.1449 x + 1.004\n",
    "\n",
    "PARAMETERS: w3 = 1.326, w2 = 0.09076, w3 = 0.1449 \n",
    "\n",
    "HYPER-PARAMETERS = degree 3 polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1o_AbBOg-97W"
   },
   "source": [
    "## 1. Regularisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IjtVOUOWlOl"
   },
   "source": [
    "The aim of this exercise is to see the behind-the-scenes code for linear and polynomial regression, that corresponds to the \n",
    "equations\tseen in the lecture. Moreover, we will see the fantastic role that regularisation technique can play in fighting against over-fitting and getting models with improved generalisation (lower variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KnxdjqkXtSg"
   },
   "source": [
    "0. The following script defines a function that we will use to generate training and test samples from an underlying true model that we want to learn! The true model is a polynomial, and we generate our dataset instances by sampling from this true model and adding some noise to it. (Note that this is of course an artificial set-up, with the purpose of this lab exercise, to see the effect of regularisation. In a practical scenario, we of course don't know the true model and our task is to indeed \"learn\" it!). \n",
    "\n",
    "  Run the following code cell to load the function **definition** (note that there will not be any output). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZR50MWx_BZr"
   },
   "outputs": [],
   "source": [
    "# You don't have to be concerned about the detail of the following function!\n",
    "\n",
    "def utilCreatePolyData(nTrain=10, \n",
    "                       nTest=20,\n",
    "                       PolynomialCoefficients=[1,0,0,1],\n",
    "                       rndseed=0):\n",
    "  '''\n",
    "  Function to generate some artificials samples for our test and train data.\n",
    "  The data is generated by sampling from a true underlying model as a polynomial \n",
    "  and adding some noise (Gaussian with mean zero and `sigma`=0.1) to them.\n",
    "  \n",
    "  Parameters:\n",
    "    nTrain (int) : number of the training data points to generate\n",
    "    nTest (int) : number of the test data points to generate\n",
    "    PolynomialCoefficients (list) : the coefficients of the true polynomial\n",
    "    rndseed (int) : seed for the random number generator --for repeatability--\n",
    "  \n",
    "  Retunrns:\n",
    "    xTrain, yTrain (list) : training attributes and labels (with length of `nTrain`)\n",
    "    xTest, yTest (list) : test attributes and labels (with length of `nTest`)\n",
    "    xTrue, yTrue (list) : samples from the true underlying model (length of 201)\n",
    "  '''\n",
    "  \n",
    "  np.random.seed(rndseed) \n",
    "  \n",
    "  # just to make sure we have enough samples to choose from:\n",
    "  total_number_of_samples = max(201, 10*(nTrain+nTest))\n",
    "  \n",
    "  xTrue  = np.linspace(start=-1, stop=1, num=total_number_of_samples)\n",
    "  yTrue  = np.polynomial.polynomial.polyval(xTrue, PolynomialCoefficients)\n",
    "  sigma    = 0.1\n",
    "  idx    = np.random.permutation(np.arange(total_number_of_samples))\n",
    "  idxTrain = idx[0:nTrain]\n",
    "  xTrain = xTrue[idxTrain] \n",
    "  yTrain = yTrue[idxTrain] + np.random.randn(nTrain)*sigma\n",
    "  \n",
    "  idxTest = idx[nTrain:(nTrain+nTest)]\n",
    "  xTest = xTrue[idxTest]\n",
    "  yTest = yTrue[idxTest] + np.random.randn(nTest)*sigma\n",
    "\n",
    "  return xTrain, yTrain, xTest, yTest, xTrue, yTrue\n",
    "\n",
    "# for testing the function:\n",
    "xTrain, yTrain, xTest, yTest, xTrue, yTrue = utilCreatePolyData(nTrain=3, nTest=2)\n",
    "print(xTrain, yTrain, xTest, yTest)\n",
    "print( xTrue[:4], yTrue[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-jKca1Nd0RE"
   },
   "source": [
    "1. The following script defines another useful function that extends the attributes with polynomials of that attribute for a given order. For instance, if the samples only have one attribute (so `X` is `N-by-1` where `N` is the number of items in our dataset), then the output of `util_makeGramMatPoly(X, 2)` is an `N-by-3` matrix, where the first column is just all constant ones, the second column is the same attributes as in `X`, and the third column is the square of the values in X. Similarly, `util_makeGramMatPoly(X, 3)` will be an `N-by-4` matrix, where the first column is just all ones, the second column is the original attributes in X, the third column is the squares, and the fourth is their cubes. Recall that this was our trick to apply the same technique for finding the best multivariate linear regression to polynomial regression.\n",
    "\n",
    "  This function is also implemented in `skitlearn` library as `sklearn.preprocessing.PolynomialFeatures`. You can read more about it along with examples [on its documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html/). If you are interested in its actual implementation, as with any other Python library, you can check its [source code](https://github.com/scikit-learn/scikit-learn/blob/1495f6924/sklearn/preprocessing/data.py#L1326)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OxfyCo0TyS8K"
   },
   "outputs": [],
   "source": [
    "# Again, you don't have to be concerned with the detail of this function!\n",
    "\n",
    "from scipy.special import comb as choose\n",
    "from itertools import chain, combinations_with_replacement\n",
    "def util_makeGramMatPoly(X, order):\n",
    "  '''\n",
    "  Returns a new matrix whose columns are the columns of the input matrix `X`, as \n",
    "  well as all the monomials of those columns, up to the degree `order`.\n",
    "\n",
    "  For example, if the columns of X represent attributes of `age` and `weight`,\n",
    "  i.e., if `X = [age, weight]`, then the output of `util_makeGramMatPoly(X, 2)` \n",
    "  will be `[1, age, weight, age**2, age*weight, weight**2]`.\n",
    "\n",
    "  Parameters:\n",
    "    X : numpy array, shape (n_samples, n_features)\n",
    "      The matrix of dataset (size: `N*p`) where `N` is the number of samples \n",
    "      (instances), and each one is described with `p` features (attributes).\n",
    "    \n",
    "    order : int\n",
    "      The maximum degree (maximum power) of the monomial to be built from the \n",
    "      columns of X. \n",
    "\n",
    "  Returns:\n",
    "    X_Extended : numpy array, shape (n_samples, n_extended_features) \n",
    "      The extended dataset extended with monomial features, prepared for \n",
    "      polynomial regression. The number of extended features is the number of \n",
    "      possible ways to construct monomials of up to degree `order` from the \n",
    "      columns of X, including zero powers.`\n",
    "  '''\n",
    "\n",
    "  \n",
    "  if len(np.shape(X)) == 1:\n",
    "    X = np.reshape(X,(-1,1))\n",
    "  \n",
    "  n_samples, n_features = X.shape\n",
    "\n",
    "  # I sat down and worked out the number in closed-form  -- just for fun! -- \n",
    "  n_output_features = int((order+1)*choose(order+n_features, order+1)/n_features)\n",
    "\n",
    "  X_Extended = np.empty(shape=(n_samples, n_output_features))\n",
    "  combinations = chain.from_iterable(combinations_with_replacement(range(n_features), i)\n",
    "                                     for i in range(0, order+1))\n",
    "  for i, comb in enumerate(combinations):\n",
    "    X_Extended[:, i] = X[:, comb].prod(axis=1)\n",
    "                           \n",
    "  return X_Extended\n",
    "\n",
    "\n",
    "# for testing the function:\n",
    "X = np.array([[1,2],[3,4],[-1,5]])\n",
    "print('Example Input:\\n')\n",
    "print(X)\n",
    "print('\\nIts Output:\\n')\n",
    "print(util_makeGramMatPoly(X, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnwTf5emAHts"
   },
   "source": [
    "2. In the following script, we first generate training and test\n",
    "samples from a cubic polynomial (as the true underlying model, which some noise is added to it). We then fit polynomials of different degrees\n",
    "to the train data and evaluate it on the test data. There are two differences here compared to the previous section:\n",
    "\n",
    "- We allow the loss function (to quantify the goodness of fit) to have a regularisation term as well as just the mean-squared-error. Recall that this term penalises the use of weights (except for the intercept).  \n",
    "\n",
    "- Instead of using an available high-level function to do the fitting (finding the best model), we directly implement the analytical solution that we presented during the lecture! (i.e., the \"closed form\" solution for the weights of the model that yield the minimum mean squred error). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZvEgw28oydu"
   },
   "source": [
    "---\n",
    "> **Q4:** Look over the code and identify the line that computes the best weight vector and compare it with the solution to polynomial regression equation in the lecture notes. Do they match? \n",
    "Note that LAMBDA (i.e., $\\lambda$) is the regularisation weight which controls the strength (importance) of the regularisation term in the overall loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBXyk1bjrgsS"
   },
   "source": [
    "> **A4:** \n",
    "\n",
    "`w_ml     = np.matmul(pinv(LAMBDA*I + np.matmul(phiTrain.T, phiTrain)), np.matmul(phiTrain.T, yTrain))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvoGPdw0BuZB"
   },
   "source": [
    "> **Q5:** Now if you are up for a rather difficult question: can you explain the reason behind the following line in the code: ```I[0,0] = 0```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9om0OKcKCRFP"
   },
   "source": [
    "> **A5:** \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9u59vHAH2DX"
   },
   "outputs": [],
   "source": [
    "message = \"Data Mining -- Lab 1 part 2: Polynomial Regression with Regularisation\"\n",
    "print(message)\n",
    "print('-'*len(message)+'\\n')\n",
    "\n",
    "from scipy.linalg import pinv\n",
    "# pinv: takes the (pseudo)-inverse (generalised inverse) of a matrix.\n",
    "# the same function is also available from numpy: numpy.linalg.pinv\n",
    "\n",
    "\n",
    "grid = widgets.Grid(1, 3)\n",
    "\n",
    "# first, to generate our train and test data sets:\n",
    "xTrain, yTrain, xTest, yTest, xTrue, yTrue = utilCreatePolyData(nTrain=100,\n",
    "                                                                rndseed=0)\n",
    "# Note: change the \"rndseed\" to some other integer, say your Student ID, to get \n",
    "# fresh data, different from others!\n",
    "\n",
    "'''Perform regression with different order polynomials'''\n",
    "\n",
    "LAMBDA = 0.2 # This is the regularisation strength.\n",
    "\n",
    "for i, order in enumerate([1,3,9]):\n",
    "    phiTrain = util_makeGramMatPoly(xTrain, order)\n",
    "    phiTest  = util_makeGramMatPoly(xTest, order)  \n",
    "    phiAll   = util_makeGramMatPoly(xTrue, order)\n",
    "    I        = np.eye(order+1)\n",
    "    I[0,0] = 0\n",
    "    \n",
    "    w_ml     = np.matmul(pinv(LAMBDA*I + np.matmul(phiTrain.T, phiTrain)), np.matmul(phiTrain.T, yTrain))\n",
    "    \n",
    "    \n",
    "    with grid.output_to(0, i):\n",
    "      plt.plot(xTrain, yTrain,'.', alpha=0.8, label='Train data')\n",
    "      plt.plot(xTest, yTest,'*', alpha=0.8, label='Test data')\n",
    "      plt.plot(xTrue, np.matmul(phiAll, w_ml), '-', \n",
    "               alpha=0.8, label='Learned model', linewidth=2)\n",
    "      plt.plot(xTrue, yTrue,'--', label='True model', linewidth=2)\n",
    "\n",
    "      \n",
    "      plt.title('Order = {}, $\\lambda$={}'.format(order, LAMBDA))\n",
    "      plt.xlabel(\"x\", fontsize=14)\n",
    "      plt.ylabel(\"y\", fontsize=14)\n",
    "      plt.xlim(-1.1,1.1)\n",
    "      plt.ylim(-0.1,2.1)\n",
    "      plt.grid(alpha=0.2)\n",
    "      plt.legend(loc='upper left', fontsize=12)\n",
    "      plt.show()\n",
    "      ERROR_TRAIN = np.matmul(phiTrain, w_ml) - yTrain\n",
    "      ERROR_TEST = np.matmul(phiTest, w_ml) - yTest #0\n",
    "      print('Train MSE = {:8.4f}'.format(np.dot(ERROR_TRAIN.T,ERROR_TRAIN)/len(ERROR_TRAIN)))\n",
    "      print('Test MSE = {:8.4f}'.format(np.dot(ERROR_TEST.T,ERROR_TEST)/len(ERROR_TEST)))\n",
    "      print('\\nFitted Model:\\n{}\\n---'.format(np.poly1d(np.flip(w_ml), variable='x')))\n",
    "      print(\"w'*w = {:8.4f}\".format(np.dot(w_ml.T, w_ml)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iba-JUSupw2O"
   },
   "source": [
    "---\n",
    "> **Q6:** There is an intentional mistake in the code: the MSE for the test data is not computed correctly. Fix it. Same hints as before applies here (look how the MSE is computed for the train data, and accordingly write the code for the test data. Once done, peek ahead in the next code cell for double-checking where the code is provided for you.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ma7eAbDCsIhJ"
   },
   "source": [
    "> **Q7:** Try different values for $\\lambda$ and observe the fits as well as the reported train and test errors, e.g., for the choice of LAMBDA in $(0, 0.001, 0.01, 0.1, 1, 10)$. You will need to re-run the script for each new value of LAMBDA. In particular, take note of the effect of $\\lambda$ on cases where we have under-fitting and cases where we have  over-fitting in the absence of regularisation (i.e., when $\\lambda=0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7xUX7FQ161_"
   },
   "source": [
    "> **A7:** \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aedshp_z2ZMK"
   },
   "source": [
    "3. For convenience, the following script puts the different models in a grid to allow easier comparison (we are doing a grid-search!). Here, we have two **hyper-parameters** (what are they?) \n",
    "\n",
    "  For each case (for each combination of the hyper-parameters), the best model is fit and its performance on train and test dataset are reported. Another value that is reported is the sum of the squares of the weights are also reported, i.e., $\\sum_{i=1}^{p}w^2_i$, which is equal to $\\vec{w}^{T}.\\vec{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFkHWZdphzzG"
   },
   "outputs": [],
   "source": [
    "def GridPlotDifferentOrdersDiffernetRegularisation(LAMBDAS=[0, 0.001, 0.01, 0.1, 1, 10],\n",
    "                                                   ORDERS= [1,2,3,9],\n",
    "                                                   N_TrainPoints=10):\n",
    "\n",
    "  grid = widgets.Grid(len(LAMBDAS)+1, len(ORDERS)+1)\n",
    "\n",
    "  for j, order in enumerate(ORDERS):\n",
    "    with grid.output_to(0, j+1):\n",
    "      print('order={:d}'.format(order))\n",
    "\n",
    "\n",
    "  xTrain, yTrain, xTest, yTest, xTrue, yTrue = utilCreatePolyData(nTrain=N_TrainPoints)\n",
    "  # Parameter here specifies how many points to generate.\n",
    "\n",
    "  for i, LAMBDA in enumerate(LAMBDAS):\n",
    "    with grid.output_to(i+1, 0):\n",
    "      print('lambda={:5.4f}'.format(LAMBDA))\n",
    "\n",
    "    for j, order in enumerate(ORDERS):\n",
    "      phiTrain = util_makeGramMatPoly(xTrain, order)\n",
    "      phiTest  = util_makeGramMatPoly(xTest, order)  \n",
    "      I        = np.eye(order+1)\n",
    "      I[0, 0] = 0\n",
    "      w_ml     = np.matmul(pinv(LAMBDA*I + np.matmul(phiTrain.T, phiTrain)),np.matmul(phiTrain.T, yTrain))\n",
    "\n",
    "      with grid.output_to(i+1, j+1):\n",
    "        plt.plot(xTrain, yTrain,'.', alpha=0.8, label='Train data')\n",
    "        plt.plot(xTest, yTest,'*', alpha=0.8, label='Test data')\n",
    "        plt.plot(xTrue, np.polynomial.polynomial.polyval(xTrue, w_ml),'-',\n",
    "                   linewidth=2, alpha=0.8, label='Learned model')\n",
    "        plt.plot(xTrue, yTrue, '--', label='True model', linewidth=2)\n",
    "        \n",
    "\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.xlim(-1.1,1.1)\n",
    "        plt.ylim(0,2)\n",
    "        plt.grid(alpha=0.2)\n",
    "        plt.legend(loc='upper left', fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "        ERROR_TRAIN = np.matmul(phiTrain, w_ml) - yTrain\n",
    "        ERROR_TEST = np.matmul(phiTest, w_ml) - yTest\n",
    "        print('MSE Train = {:8.4f}'.format(np.dot(ERROR_TRAIN.T,ERROR_TRAIN)/len(ERROR_TRAIN)))\n",
    "        print('MSE Test = {:8.4f}'.format(np.dot(ERROR_TEST.T,ERROR_TEST)/len(ERROR_TEST)))\n",
    "        print(\"w'*w = {:8.4f}\".format(np.dot(w_ml.T, w_ml)))\n",
    "        \n",
    "# run it with default values:        \n",
    "GridPlotDifferentOrdersDiffernetRegularisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdRkWGLX6CWv"
   },
   "source": [
    "---\n",
    "---\n",
    "####<font color=\"maroon\"><b>Exercise 5: Focus on order=9. Describe AND explain the trend of each of the metrics below with respect to increasing values of $\\lambda$ (that is, first describe what the effect of increasing $\\lambda$ from zero upward is it on the parameter in question and then explain briefly and clearly the reasons behind it):   [1 mark]\n",
    "  (a) TRAIN MSE <br>\n",
    "  (b) $\\vec{w}^T.\\vec{w}$<br> \n",
    "  (c) TEST MSE\n",
    "</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "io9Q-yBB9bwA"
   },
   "source": [
    "####<font color=\"maroon\"><b>Exercise 6: Now suppose that instead of 10 training instances, we had access to 100 train instances. Run the following script and inspect the change in the test error. Describe and explain the effect of having more training data on the test error (test MSE) and over-fitting. </b> <b>[1 mark]</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSwD4RS9HhWN"
   },
   "outputs": [],
   "source": [
    "GridPlotDifferentOrdersDiffernetRegularisation(N_TrainPoints=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77P4iHK1RnIm"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg7aJRlwJeiG"
   },
   "source": [
    "## 2. Validation (and Cross-Validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyFC4eQBRrNV"
   },
   "source": [
    "The point of this exercise is to clarify the roles of train, validation, and testing data in the process of performing machine learning and data mining.\n",
    "\n",
    "\n",
    "So far, we have been training a model (finding the best fit, the best parameters, for a given set of hyper-parameters) on `train` data, and then evaluating it on `test` data, since they were unseen by the model. However, if we then pick the best model (the best hyper-parameter combination) among our fitted models based on the performances on the test data, we are at the risk of over-fitting the hyper-parameters to the test data! That is, we may think that this is the best hyper-parameter combination, but in fact, it just happens to be doing the best on the particular test data we have. Although this is much less serious than over-fitting to the train data, importantly, we do not have an untainted measure of the performance of the ``best'' model when faced with truly new and unseen data, i.e., how well does your model *generalise* (because we have tainted our test data by peeking into it for tuning our hyper-parameter). \n",
    "\n",
    "Recognising this problem, the best practice is to partition our dataset into not just two subsets (train and test), but to 3 subsets: (**train**, **validation**, and **test**). \n",
    "\n",
    "The process of finding the best model and getting an honest (untainted) measure of its performance is as follows:\n",
    "\n",
    "0.   Split the dataset into 3 subsets: `train`, `validation`, and `test`;\n",
    "1.   For a given set of hyper-parameters, find the best fit using the `train` dataset; then apply the model to the `validation` dataset to get a measure of its performance;\n",
    "2.   Vary the hyper-parameters (i.e., do a \"grid-search\") and pick the hyper-parameter combination that performs the best on the `validation` dataset.\n",
    "3.   Then in order to get a performance measure of this selected model, apply it to the `test` dataset.\n",
    "\n",
    "There can be some variation of this **model selection** process: \n",
    "\n",
    "- (v1) In step 0 above, the partition of the dataset between `train` and `validation` was fixed when searching for the best hyper-parameter; instead, it can be randomised each time after step 1, i.e., for each new candidate for hyper-parameter values.\n",
    "\n",
    "- (v2) Once the hyper-parameters are selected using validation (after step 2 above), then the train and validation datasets can be combined, and a model is fit to this larger dataset using this hyper-parameter values (and then applied to the test dataset, as before, to get a measure of its performance when facing new data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCdey7PJcXnw"
   },
   "source": [
    "---\n",
    "> **Q8:** As a thought-provoking (challenging) question, for each of the variations above, which we just labelled (v1) and (v2), try to argue its pros and cons, i.e., discuss its potential advantages and disadvantages of using that variation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-PDwcHsgHu7"
   },
   "source": [
    "> **A8:** \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oOBFZvSR_vz"
   },
   "source": [
    "0. This script contains a simple validation procedure to select the parameter lambda of a regularisation problem. The validation procedure splits the input data into two subsets: trainset and valset. It then searches within a range of values (hyper-parameters) and decides the best one to use based on the resulting validation MSE. Note that\n",
    "`np.logspace(start=-3, stop=1, num=5)` creates the array of $[10^{-3}, 10^{-2} , 10^{-1} , 10^0 , 10^1 ]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flTfVNSTRtc3"
   },
   "outputs": [],
   "source": [
    "# First, starting with our artificial example: \n",
    "xTrain, yTrain, xTest, yTest, xTrue, yTrue = utilCreatePolyData(nTrain=100, \n",
    "                                                                 PolynomialCoefficients=[1,-1,0,0,0,1],\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTDVyi1tJ2xE"
   },
   "outputs": [],
   "source": [
    "LAMBDAS = np.logspace(start=-3, stop=1, num=5)\n",
    "LAMBDAS = np.insert(LAMBDAS, 0, 0)\n",
    "order = 9\n",
    "\n",
    "bestLAMBDA = -1\n",
    "minerr = np.Infinity\n",
    "nTrain = len(yTrain)\n",
    "RNDM = np.random.RandomState(seed=0)\n",
    "\n",
    "for LAMBDA in LAMBDAS:\n",
    "  # Split the train samples into training and validation dataset\n",
    "  ids = RNDM.permutation(np.arange(nTrain))\n",
    "  num_train = int(np.ceil(nTrain*0.75))\n",
    "  xtrainset = xTrain[ids[:num_train]]\n",
    "  ytrainset = yTrain[ids[:num_train]]\n",
    "  xvalset   = xTrain[ids[num_train:]]\n",
    "  yvalset   = yTrain[ids[num_train:]]\n",
    "  phitrain  = util_makeGramMatPoly(xtrainset, order)\n",
    "  phival    = util_makeGramMatPoly(xvalset, order)\n",
    "  phitest   = util_makeGramMatPoly(xTest, order)\n",
    "  I         = np.eye(order+1)\n",
    "  I[0, 0]   = 0\n",
    "\n",
    "  # This line learns the regression model for a given lambda.\n",
    "  w_map     = np.matmul(pinv(LAMBDA*I + np.matmul(phitrain.T,phitrain)),\n",
    "                        np.matmul(phitrain.T,ytrainset)) \n",
    "    \n",
    "  # The next line will help decide which is the best lambda.   \n",
    "  #--- FIX ME: COMMENT OUT TWO OF THE LINES BELOW, SO EXACTLY ONE IS ENABLED ---  \n",
    "#  SSE = np.sum(np.power(ytrainset - np.matmul(phitrain, w_map), 2))\n",
    "#  SSE = np.sum(np.power(yvalset - np.matmul(phival, w_map), 2)) \n",
    "#  SSE = np.sum(np.power(yTest - np.matmul(phitest, w_map), 2))\n",
    "    \n",
    "  print('Lambda: {0:1.5f}, CV SSE: {1:1.5f}.'.format(LAMBDA, SSE), end='')\n",
    "  if SSE < minerr:\n",
    "    print(' * New best')\n",
    "    bestLAMBDA = LAMBDA\n",
    "    minerr = SSE\n",
    "  else:\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjCkjKutTxH-"
   },
   "source": [
    "1. The incomplete part of this script is missing which portion of the data we\n",
    "should use as the criteria for selecting lambda. It could be Train, Val or Test.\n",
    "Fix this section by commenting out two lines, leaving the correct line in, and\n",
    "run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qS4OmjlGULCM"
   },
   "source": [
    "---\n",
    "---\n",
    "####<font color=\"maroon\"><b>Exercise 7: Which is the correct way to complete the script and calculate the variable SSE? Explain what each of the three options to calculate SSE would do and justify your choice. What is the resulting train and test errors? </b> <b>[0.5 mark]</b> </font>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nc1_jy51huje"
   },
   "source": [
    "### Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3TQwLQRRrpo"
   },
   "outputs": [],
   "source": [
    "phi        = util_makeGramMatPoly(xTrain, order)\n",
    "best_w_map = np.matmul(pinv(bestLAMBDA*I+np.matmul(phi.T, phi)), \n",
    "                       np.matmul(phi.T, yTrain)) \n",
    "\n",
    "phitest    = util_makeGramMatPoly(xTest, order) \n",
    "train_MSE = np.sum(np.power(yTrain - np.matmul(phi, best_w_map), 2)) \n",
    "test_MSE  = np.sum(np.power(yTest - np.matmul(phitest, best_w_map), 2)) \n",
    "\n",
    "\n",
    "\n",
    "plt.plot(xTrain, yTrain,'.', alpha=0.4, label='Train data')\n",
    "plt.plot(xTest, yTest,'*', alpha=0.6, label='Test data')\n",
    "plt.plot(xTrue, yTrue, '--', label='True model')\n",
    "plt.plot(xTrue, np.polynomial.polynomial.polyval(xTrue, best_w_map),'-',\n",
    "           alpha=0.8, label='Learned model')\n",
    "\n",
    "plt.xlabel(\"x\", fontsize=14)\n",
    "plt.ylabel(\"y\", fontsize=14)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r989xNSAQ7mG"
   },
   "source": [
    "## 3.   A Real application of multivariate regression &mdash; Weka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5mZeIb_U14M"
   },
   "source": [
    ">#### 1. Start Weka Explorer. \n",
    ">\n",
    ">\n",
    ">#### 2. Load last week’s $\\texttt{LondonCars.csv}$ dataset (Explore → Preprocess → Open).\n",
    ">\n",
    ">\n",
    ">#### 3. This time we will use the categorical variables. However first remove $Model$ (check its Attribute view box and then press remove). This will speed up the next steps significantly.\n",
    ">\n",
    ">\n",
    ">#### 4. Observe the available regression models: Classify → Choose → Functions. Choose $LinearRegression$ for now.\n",
    ">\n",
    ">\n",
    ">#### 5. Make sure price is selected as the target.\n",
    ">\n",
    ">\n",
    ">#### 6. Observe that under \"Test Options\" Weka can report the results on:\n",
    ">>i) the train data; \n",
    "<br>\n",
    ">>ii) a test split created by holding out a specified percentage, or;\n",
    "<br>\n",
    ">>iii) cross-validation by averaging the performance over many folds.\n",
    ">\n",
    ">\n",
    ">#### 7. Select use train set and start. Observe the resulting MAE.\n",
    ">>\n",
    ">>\n",
    ">>**a.** Try also 2-fold cross-validation and **50%** test split (last option).\n",
    ">>\n",
    ">>**b.** Note the train error, test error, and the difference between them. (Using the results list you can review previous settings and outputs).\n",
    ">\n",
    ">\n",
    ">#### 8. Now let's try a strong non-linear model: Classify → Choose → Trees → M5P.\n",
    ">>**a.** Again using the \"Test options\" panel, get the train error; **50%** split test error; and 2-fold cross-validation error.\n",
    ">>\n",
    ">>**b.** Notice the errors are now better than the linear regression model.\n",
    ">>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S70MBNvXPuXt"
   },
   "source": [
    "---\n",
    "####<font color=\"maroon\"><b>Exercise 8: Compare the training, validation and the test errors in both the linear model and the M5P model. First, explain the differences between the numerical values of each error separately for the linear model and for the M5P model. Then, bearing in mind that the M5P model is more complex than the linear model, explain why the numerical values of the errors seem to behave differently for the linear model and for the M5P model. [1 mark]</b> </font>\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECS766_Lab02_3.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
