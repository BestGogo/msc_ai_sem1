{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMi4lrzybvKJ"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function  # needed for Python 2\n",
    "from __future__ import division        # needed for Python 2\n",
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "HFaZHfGyavE0",
    "outputId": "5e6827ba-cec7-468f-8515-a1cc0d5050fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "# !pip install sklearn\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8S208_0bvKT"
   },
   "outputs": [],
   "source": [
    "# load data from a file and append it to the rawData\n",
    "\n",
    "def loadData(path, Text=None):\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        reader.next() # ignore header\n",
    "        for line in reader:\n",
    "            (Id, Text, Rating, VerPurchase, Label) = parseReview(line)\n",
    "            rawData.append((Id, Text, Rating, VerPurchase, Label))\n",
    "            preprocessedData.append((Id, preProcess(Text), Rating, VerPurchase, Label))\n",
    "            #print(preProcess(Text))\n",
    "\n",
    "        \n",
    "def splitData(percentage):\n",
    "    dataSamples = len(rawData)\n",
    "    halfOfData = int(len(rawData)/2)\n",
    "    trainingSamples = int((percentage*dataSamples)/2)\n",
    "    for (index, Text,_,_, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
    "        trainData.append((toFeatureVector(preProcess(Text),index),Label))\n",
    "    for (index, Text,_,_, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
    "        testData.append((toFeatureVector(preProcess(Text),index),Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzsFgoSnbvKb"
   },
   "outputs": [],
   "source": [
    "# QUESTION 1\n",
    "import csv,re\n",
    "# Convert line from input file into an id/text/label tuple\n",
    "def parseReview(reviewLine):\n",
    "    \"\"\"\n",
    "    reviewLine is a list\n",
    "    \"\"\"\n",
    "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
    "    doc_id = int(reviewLine[0])\n",
    "    label = reviewLine[1]\n",
    "    review_text = reviewLine[8]\n",
    "    #print((doc_id, review_text, label))\n",
    "    return (doc_id, review_text, reviewLine[2], reviewLine[3] ,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrzmMXxDbvKh"
   },
   "outputs": [],
   "source": [
    "# TEXT PREPROCESSING AND FEATURE VECTORIZATION\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "stopwords = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Input: a string of one review\n",
    "def preProcess(text):\n",
    "    # Should return a list of tokens    \n",
    "    # CHANGE THE CODE BELOW\n",
    "    # # word tokenisation\n",
    "    # text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
    "    # text = re.sub(r\"([.,;:!?'\\\"“\\(])(\\w)\", r\"\\1 \\2\", text)\n",
    "    # #print \"tokenising:\", text\n",
    "    # tokens = re.split(r\"\\s+\",text)\n",
    "    # # normalisation\n",
    "    # text = re.sub(r\"(\\S)\\1\\1+\",r\"\\1\\1\\1\", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z0-9]+',' ',text)\n",
    "    tokens = text.split(' ')\n",
    "    # stop word removal\n",
    "    tokens = [w for w in tokens if w not in stopwords]\n",
    "    # Stemming\n",
    "    tokens = [porter.stem(w) for w in tokens]\n",
    "    # tokens = [porter.stem(w) if porter.stem(w) in set(words.words()) else w for w in tokens ] \n",
    "    # remove speacial char\n",
    "    tokens = [w for w in tokens if w is not '' ]\n",
    "\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_1ydFtEgbvKn",
    "outputId": "d163fb45-b096-4591-efcb-6211e7447aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ['least', 'think', 'product', 'save', 'day', 'keep', 'around', 'case', 'need', u'someth'], '4', 'N', '__label1__'), (2, ['lithium', u'batteri', u'someth', 'new', u'introduc', 'market', u'averag', u'develop', 'cost', u'rel', 'high', 'stallion', u'compromis', u'qualiti', u'provid', 'us', 'best', 'low', 'cost', 'br', u'mani', 'built', u'technic', u'assist', 'act', 'like', 'sensor', 'particular', 'fort', u'batteri', u'keep', 'phone', u'charg', u'work', u'everi', u'voltag', 'high', u'voltag', 'never', u'risk'], '4', 'Y', '__label1__'), (3, [u'purchas', 'swing', u'babi', '6', u'month', u'pretti', 'much', 'grown', 'loud', 'swing', 'well', u'beauti', 'though', 'love', u'color', 'lot', u'set', 'think', 'worth', 'money'], '3', 'N', '__label1__'), (4, [u'look', u'inexpens', 'desk', 'calcolatur', u'work', u'everyth', 'need', u'issu', u'tilt', u'slightli', 'one', 'side', 'hit', u'key', u'rock', u'littl', 'bit', 'big', 'deal'], '4', 'N', '__label1__'), (5, ['use', 'twice', 'week', u'result', 'great', u'use', 'teeth', u'whiten', u'solut', u'result', 'would', 'use', 'least', 'three', u'time', 'week', 'keep', u'use', u'potenc', u'solut', 'also', u'techniqu', u'tray', u'keep', u'everyth', 'teeth', 'mouth'], '4', 'N', '__label1__'), (6, ['sure', u'suppos', 'would', 'recommend', u'littl', 'research', u'cultur', u'use', u'pipe', 'plan', u'give', 'gift', u'use'], '3', 'N', '__label1__'), (7, [u'pleas', 'ping', 'pong', u'tabl', '11', 'year', 'old', '13', 'year', 'old', 'blast', u'plu', u'lot', u'famili', u'entertain', u'plu', 'better', u'kid', u'sit', 'video', u'game', 'day', 'friend', 'put', u'togeth', u'believ', u'challeng', u'noth', 'could', u'handl'], '4', 'N', '__label1__'), (8, ['great', 'vitamin', 'c', 'serum', u'realli', 'like', 'oil', u'feel', u'sticki', u'use', 'last', 'week', 'recent', 'bug', u'bite', u'help', 'heal', 'skin', 'faster', 'normal'], '4', 'Y', '__label1__'), (9, [u'use', 'tide', u'pod', u'laundri', u'deterg', u'mani', u'year', 'great', u'deterg', 'use', 'nice', 'scent', 'leaver', u'cloth', u'smell', 'fresh'], '4', 'N', '__label1__'), (10, [u'everybodi', u'want', 'fall', u'promis', u'rel', 'unheard', 'brand', 'even', 'say', 'non', u'exist', u'compani', 'look', 'amateur', u'label', u'product', 'ask', 'would', 'trust', 'kind', 'amateur', 'stuff', 'way', u'wast', 'money'], '1', 'N', '__label1__')]\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 2\n",
    "rawData = []\n",
    "preprocessedData = []\n",
    "loadData('amazon_reviews.txt')\n",
    "print(preprocessedData[0:10])\n",
    "featureDict = {} # A global dictionary of features\n",
    "import collections\n",
    "alltokens =[]\n",
    "for i in preprocessedData:\n",
    "    alltokens.extend(i[1])\n",
    "featureDict = collections.Counter(alltokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "OHJqeJEadKmj",
    "outputId": "19494fac-1f10-4152-fe4b-3762591b0386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length of tokens 35.214285714285715\n",
      "Median of tokens 22.0\n",
      "Mode of tokens ModeResult(mode=array([12]), count=array([1013]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "length_of_token = []\n",
    "for i in preprocessedData:\n",
    "    length_of_token.append(len(i[1]))\n",
    "\n",
    "print(\"Avg length of tokens\", np.mean(length_of_token))\n",
    "print(\"Median of tokens\",np.median(length_of_token))\n",
    "print(\"Mode of tokens\",stats.mode(length_of_token))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqTzJXKoGtjO"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def toFeatureVector(tokens,index=None):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    adict = {}\n",
    "    total_no_of_words = sum(featureDict.values())\n",
    "    total_no_of_reviews = len(rawData)\n",
    "\n",
    "    for i in tokens[:22]:\n",
    "      count = 0\n",
    "      for line in rawData:\n",
    "        if i in line:\n",
    "          count = count+1\n",
    "      adict[i] = (featureDict[i]/total_no_of_words)*math.log(float(1 + total_no_of_reviews) / (1 + count))\n",
    "    if index is not None:\n",
    "      for i in preprocessedData:\n",
    "        if i[0] == index:\n",
    "          adict['raiting'] = i[2]\n",
    "          adict['verPur'] = 1 if i[3] == 'Y' else 0\n",
    "    return adict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "Q10d1qjSnEwK",
    "outputId": "4191fe4a-3586-40b9-ab9c-2211499feaab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'around': 0.01627094162211614,\n",
       " 'case': 0.017684050695997197,\n",
       " 'day': 0.025853166961195294,\n",
       " 'keep': 0.020294937937263148,\n",
       " 'least': 0.005652436295524218,\n",
       " 'need': 0.038598064989436805,\n",
       " 'product': 0.06018498836567692,\n",
       " 'raiting': '4',\n",
       " 'save': 0.006459927194884821,\n",
       " u'someth': 0.01531541072453943,\n",
       " 'think': 0.020792890658535516,\n",
       " 'verPur': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = ['least', 'think', 'product', 'save', 'day', 'keep', 'around', 'case', 'need', u'someth']\n",
    "toFeatureVector(token,index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIWirF8ebvKu"
   },
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "def trainClassifier(trainData):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMveQZlVbvKz"
   },
   "outputs": [],
   "source": [
    "# QUESTION 3\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(lr, boston.data, boston.target, cv=7, scoring='neg_mean_squared_error')\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "def crossValidate(dataset, folds):\n",
    "    shuffle(dataset)\n",
    "    cv_results = []\n",
    "    foldSize = int(len(dataset)/folds)\n",
    "    for i in range(0,len(dataset),foldSize):\n",
    "      valD = dataset[i:i+foldSize]\n",
    "      testD = dataset[:i]+dataset[i+foldSize:] #list(set(dataset)-set(dataset[i:i+foldSize]))\n",
    "      classi = trainClassifier(testD)\n",
    "      print('predicting')\n",
    "      y_true = map(lambda t: t[1], valD)\n",
    "      y_pred = predictLabels(valD,classi)\n",
    "      print(precision_recall_fscore_support(y_true, y_pred, average='macro'))\n",
    "      print(accuracy_score(y_true,y_pred))\n",
    "      # trainClassifier()\n",
    "      # predictLabels()\n",
    "      # break; # Replace by code that trains and tests on the 10 folds of data in the dataset\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TjsRDuU3U8oG",
    "outputId": "7055a1d9-9371-4d48-e7a5-5a0fba47eb3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z=['a','b','c','d','e','f','g','h']\n",
    "# for i in range(0,len(z),2):\n",
    "#   print(z[i:i+2],list(set(z)-set(z[i:i+2])))\n",
    "#   print(z[i:i+2],z[:i]+z[i+2:])\n",
    "#   print('\\n')\n",
    "\n",
    "tokens = ['a','b','c','d','e','f','g','h']\n",
    "tokens[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvEdW3dmbvK4"
   },
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predictLabels(reviewSamples, classifier):\n",
    "    # return classifier.classify_many(map(lambda t: toFeatureVector(preProcess(t[1])), reviewSamples))\n",
    "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
    "\n",
    "\n",
    "\n",
    "def predictLabel(reviewSample, classifier):\n",
    "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "1EV3_uOqbvK9",
    "outputId": "92e69707-0896-4752-ba5e-12ac6f018f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 21000 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
    "preprocessedData = [] # the preprocessed reviews (just to see how your preprocessing is doing)\n",
    "trainData = []        # the training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
    "testData = []         # the test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
    "\n",
    "# the output classes\n",
    "fakeLabel = 'fake'\n",
    "realLabel = 'real'\n",
    "\n",
    "# references to the data files\n",
    "reviewPath = 'amazon_reviews.txt'\n",
    "\n",
    "## Do the actual stuff\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "loadData(reviewPath) \n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "splitData(0.8)\n",
    "# We print the number of training samples and the number of features\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "wTd4zaltbvLG",
    "outputId": "9ba00299-bb08-4ba4-e7d7-9594013970fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "predicting\n",
      "(0.6008302687694803, 0.5856555634301913, 0.5680510581279862, None)\n",
      "0.5833333333333334\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5668964744128693, 0.5659718432827676, 0.5641691921920043, None)\n",
      "0.5654761904761905\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5889738695568992, 0.585050505050505, 0.5814378274055694, None)\n",
      "0.5869047619047619\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5780924935511105, 0.5567836403230197, 0.5214473697649795, None)\n",
      "0.5517857142857143\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5882509932321712, 0.5804169030062394, 0.5728128356952578, None)\n",
      "0.5839285714285715\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5698290298710909, 0.5686100828235987, 0.5666280854176755, None)\n",
      "0.5684523809523809\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5783429533429534, 0.5775649102616254, 0.5767343172054913, None)\n",
      "0.5779761904761904\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5589057680666456, 0.5463389192498695, 0.520169394200402, None)\n",
      "0.5452380952380952\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5784602300486757, 0.57380174291939, 0.5651344650009537, None)\n",
      "0.5702380952380952\n",
      "Training Classifier...\n",
      "predicting\n",
      "(0.5566994809378916, 0.5561419005233152, 0.5555043463788711, None)\n",
      "0.5571428571428572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidate(trainData, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsIBvAYmbvLM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex1_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
