{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "ex1_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMi4lrzybvKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function  # needed for Python 2\n",
        "from __future__ import division        # needed for Python 2\n",
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from random import shuffle\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8S208_0bvKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data from a file and append it to the rawData\n",
        "rawData = []\n",
        "preprocessedData = []\n",
        "def loadData(path, Text=None):\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        reader.next() # ignore header\n",
        "        for line in reader:\n",
        "            (Id, Text, Label) = parseReview(line)\n",
        "            rawData.append((Id, Text, Label))\n",
        "            preprocessedData.append((Id, preProcess(Text), Label))\n",
        "            print(preProcess(Text))\n",
        "            break;\n",
        "        \n",
        "def splitData(percentage):\n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (_, Text, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(preProcess(Text)),Label))\n",
        "    for (_, Text, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(preProcess(Text)),Label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzsFgoSnbvKb",
        "colab_type": "code",
        "outputId": "fd2fd4e3-b54c-4585-a67e-d76686d6e4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# QUESTION 1\n",
        "import csv,re\n",
        "# Convert line from input file into an id/text/label tuple\n",
        "def parseReview(reviewLine):\n",
        "    \"\"\"\n",
        "    reviewLine is a list\n",
        "    \"\"\"\n",
        "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
        "    doc_id = int(reviewLine[0])\n",
        "    label = reviewLine[1]\n",
        "    review_text = reviewLine[8]\n",
        "    print((doc_id, review_text, label))\n",
        "    return (doc_id, review_text, label)\n",
        "loadData('amazon_reviews.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'When least you think so, this product will save the day. Just keep it around just in case you need it for something.', '__label1__')\n",
            "['least', 'think', ',', 'product', 'save', 'day', '.', 'keep', 'around', 'case', 'need', 'something', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrzmMXxDbvKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEXT PREPROCESSING AND FEATURE VECTORIZATION\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words\n",
        "stopwords = stopwords.words('english')\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# Input: a string of one review\n",
        "def preProcess(text):\n",
        "    # Should return a list of tokens    \n",
        "    # CHANGE THE CODE BELOW\n",
        "    # word tokenisation\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(])(\\w)\", r\"\\1 \\2\", text)\n",
        "    #print \"tokenising:\", text\n",
        "    tokens = re.split(r\"\\s+\",text)\n",
        "    # normalisation\n",
        "    text = re.sub(r\"(\\S)\\1\\1+\",r\"\\1\\1\\1\", text)\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    # stop word removal\n",
        "    tokens = [w for w in tokens if w not in stopwords]\n",
        "    # Stemming\n",
        "    tokens = [porter.stem(w) if porter.stem(w) in set(words.words()) else w for w in tokens ]    \n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ydFtEgbvKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# QUESTION 2\n",
        "featureDict = {} # A global dictionary of features\n",
        "\n",
        "def toFeatureVector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    for word in tokens:\n",
        "      if word in featureDict.keys():\n",
        "        featureDict[word] = featureDict[word]+1\n",
        "      else:\n",
        "        featureDict[word] = 1\n",
        "\n",
        "    return featureDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIWirF8ebvKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMveQZlVbvKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# QUESTION 3\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# scores = cross_val_score(lr, boston.data, boston.target, cv=7, scoring='neg_mean_squared_error')\n",
        "\n",
        "def crossValidate(dataset, folds):\n",
        "    shuffle(dataset)\n",
        "    cv_results = []\n",
        "    foldSize = len(dataset)/folds\n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "      print(i)\n",
        "      break; # Replace by code that trains and tests on the 10 folds of data in the dataset\n",
        "    return cv_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvEdW3dmbvK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: toFeatureVector(preProcess(t[1])), reviewSamples))\n",
        "\n",
        "def predictLabel(reviewSample, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EV3_uOqbvK9",
        "colab_type": "code",
        "outputId": "e4d9b10c-4a4f-4033-903e-170c080d74cb",
        "colab": {}
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
        "preprocessedData = [] # the preprocessed reviews (just to see how your preprocessing is doing)\n",
        "trainData = []        # the training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
        "testData = []         # the test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
        "\n",
        "# the output classes\n",
        "fakeLabel = 'fake'\n",
        "realLabel = 'real'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "## Do the actual stuff\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21001 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "Now 21001 rawData, 16800 trainData, 4201 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTd4zaltbvLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsIBvAYmbvLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}